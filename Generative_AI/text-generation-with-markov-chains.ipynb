{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import Necessary Libraries","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nimport numpy as np\nimport pandas as pd\nimport os\nimport re\nimport string\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport random\nfrom datasets import load_dataset\nimport numpy as np\nimport random\nimport nltk\nfrom collections import defaultdict\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:52:45.057906Z","iopub.execute_input":"2024-11-03T15:52:45.058304Z","iopub.status.idle":"2024-11-03T15:53:10.062620Z","shell.execute_reply.started":"2024-11-03T15:52:45.058273Z","shell.execute_reply":"2024-11-03T15:53:10.061261Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"markdown","source":"## Basic Text Generation","metadata":{}},{"cell_type":"markdown","source":"### Load and Preprocess the Text Data\nFor this tutorial, we will use a sample text dataset. You can replace this with any text corpus of your choice.","metadata":{}},{"cell_type":"code","source":"# Sample text data\ntext = \"\"\"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, \nfilled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with \nnothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort.\"\"\"\n\n# Tokenize the text into words\ntokens = nltk.word_tokenize(text.lower())\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:53:27.698468Z","iopub.execute_input":"2024-11-03T15:53:27.699536Z","iopub.status.idle":"2024-11-03T15:53:27.706075Z","shell.execute_reply.started":"2024-11-03T15:53:27.699498Z","shell.execute_reply":"2024-11-03T15:53:27.704899Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['in', 'a', 'hole', 'in', 'the', 'ground', 'there', 'lived', 'a', 'hobbit', '.', 'not', 'a', 'nasty', ',', 'dirty', ',', 'wet', 'hole', ',', 'filled', 'with', 'the', 'ends', 'of', 'worms', 'and', 'an', 'oozy', 'smell', ',', 'nor', 'yet', 'a', 'dry', ',', 'bare', ',', 'sandy', 'hole', 'with', 'nothing', 'in', 'it', 'to', 'sit', 'down', 'on', 'or', 'to', 'eat', ':', 'it', 'was', 'a', 'hobbit-hole', ',', 'and', 'that', 'means', 'comfort', '.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Build the Transition Matrix\nWe will use a dictionary to store the transition probabilities.","metadata":{}},{"cell_type":"code","source":"# Build the transition matrix\ntransition_matrix = defaultdict(list)\n\nfor i in range(len(tokens) - 1):\n    transition_matrix[tokens[i]].append(tokens[i + 1])\n\n# Convert the lists to dictionaries with probabilities\nfor current_word, next_words in transition_matrix.items():\n    word_counts = defaultdict(int)\n    for word in next_words:\n        word_counts[word] += 1\n    total_count = sum(word_counts.values())\n    transition_matrix[current_word] = {word: count / total_count for word, count in word_counts.items()}\n\nprint(transition_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:53:42.818417Z","iopub.execute_input":"2024-11-03T15:53:42.818809Z","iopub.status.idle":"2024-11-03T15:53:42.828065Z","shell.execute_reply.started":"2024-11-03T15:53:42.818778Z","shell.execute_reply":"2024-11-03T15:53:42.826863Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"defaultdict(<class 'list'>, {'in': {'a': 0.3333333333333333, 'the': 0.3333333333333333, 'it': 0.3333333333333333}, 'a': {'hole': 0.2, 'hobbit': 0.2, 'nasty': 0.2, 'dry': 0.2, 'hobbit-hole': 0.2}, 'hole': {'in': 0.3333333333333333, ',': 0.3333333333333333, 'with': 0.3333333333333333}, 'the': {'ground': 0.5, 'ends': 0.5}, 'ground': {'there': 1.0}, 'there': {'lived': 1.0}, 'lived': {'a': 1.0}, 'hobbit': {'.': 1.0}, '.': {'not': 1.0}, 'not': {'a': 1.0}, 'nasty': {',': 1.0}, ',': {'dirty': 0.14285714285714285, 'wet': 0.14285714285714285, 'filled': 0.14285714285714285, 'nor': 0.14285714285714285, 'bare': 0.14285714285714285, 'sandy': 0.14285714285714285, 'and': 0.14285714285714285}, 'dirty': {',': 1.0}, 'wet': {'hole': 1.0}, 'filled': {'with': 1.0}, 'with': {'the': 0.5, 'nothing': 0.5}, 'ends': {'of': 1.0}, 'of': {'worms': 1.0}, 'worms': {'and': 1.0}, 'and': {'an': 0.5, 'that': 0.5}, 'an': {'oozy': 1.0}, 'oozy': {'smell': 1.0}, 'smell': {',': 1.0}, 'nor': {'yet': 1.0}, 'yet': {'a': 1.0}, 'dry': {',': 1.0}, 'bare': {',': 1.0}, 'sandy': {'hole': 1.0}, 'nothing': {'in': 1.0}, 'it': {'to': 0.5, 'was': 0.5}, 'to': {'sit': 0.5, 'eat': 0.5}, 'sit': {'down': 1.0}, 'down': {'on': 1.0}, 'on': {'or': 1.0}, 'or': {'to': 1.0}, 'eat': {':': 1.0}, ':': {'it': 1.0}, 'was': {'a': 1.0}, 'hobbit-hole': {',': 1.0}, 'that': {'means': 1.0}, 'means': {'comfort': 1.0}, 'comfort': {'.': 1.0}})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Text Generation\nWe will generate new text by starting with a random word and using the transition matrix to determine the next word.","metadata":{}},{"cell_type":"code","source":"def generate_text(transition_matrix, start_word, length=50):\n    current_word = start_word\n    generated_text = [current_word]\n    \n    for _ in range(length - 1):\n        next_word_probs = transition_matrix.get(current_word, None)\n        if not next_word_probs:\n            break\n        next_word = np.random.choice(list(next_word_probs.keys()), p=list(next_word_probs.values()))\n        generated_text.append(next_word)\n        current_word = next_word\n    \n    return ' '.join(generated_text)\n\n# Generate text starting with the word \"in\"\ngenerated_text = generate_text(transition_matrix, start_word=\"in\")\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T15:53:56.638086Z","iopub.execute_input":"2024-11-03T15:53:56.638502Z","iopub.status.idle":"2024-11-03T15:53:56.649660Z","shell.execute_reply.started":"2024-11-03T15:53:56.638468Z","shell.execute_reply":"2024-11-03T15:53:56.648395Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"in it to eat : it to sit down on or to eat : it to sit down on or to sit down on or to sit down on or to sit down on or to sit down on or to sit down on or to sit down on or\n","output_type":"stream"}]},{"cell_type":"code","source":"def Tokenize(txt):\n    cleaned_txt = []\n    for line in txt:\n        line = line.lower()\n        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n        tokens = word_tokenize(line)\n        words = [word for word in tokens if word.isalpha()]\n        cleaned_txt += words\n    return cleaned_txt\n \nTokens = Tokenize(English)\nprint(\"number of words = \", len(Tokens))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:07:22.583947Z","iopub.execute_input":"2024-08-08T08:07:22.584441Z","iopub.status.idle":"2024-08-08T08:10:21.909895Z","shell.execute_reply.started":"2024-08-08T08:07:22.584396Z","shell.execute_reply":"2024-08-08T08:10:21.908381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the Model","metadata":{}},{"cell_type":"code","source":"class MarkovModel:\n \n    def __init__(self, n_gram=2):\n        self.n_gram = n_gram\n        self.markov_model = {}\n \n    def build_model(self, text):\n        for i in range(len(text)-self.n_gram-1):\n            curr_state, next_state = \"\", \"\"\n            for j in range(self.n_gram):\n                curr_state += text[i+j] + \" \"\n                next_state += text[i+j+self.n_gram] + \" \"\n            curr_state = curr_state[:-1]\n            next_state = next_state[:-1]\n            if curr_state not in self.markov_model:\n                self.markov_model[curr_state] = {}\n                self.markov_model[curr_state][next_state] = 1\n            else:\n                if next_state in self.markov_model[curr_state]:\n                    self.markov_model[curr_state][next_state] += 1\n                else:\n                    self.markov_model[curr_state][next_state] = 1\n \n        # calculating transition probabilities\n        for curr_state, transition in self.markov_model.items():\n            total = sum(transition.values())\n            for state, count in transition.items():\n                self.markov_model[curr_state][state] = count/total\n \n    def get_model(self):\n        return self.markov_model","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:10:21.911034Z","iopub.status.idle":"2024-08-08T08:10:21.911433Z","shell.execute_reply.started":"2024-08-08T08:10:21.911242Z","shell.execute_reply":"2024-08-08T08:10:21.911258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"markov = MarkovModel()\nmarkov.build_model(Tokens)\nprint(\"number of states = \", len(markov.get_model().keys()))","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:10:21.91316Z","iopub.status.idle":"2024-08-08T08:10:21.91356Z","shell.execute_reply.started":"2024-08-08T08:10:21.913383Z","shell.execute_reply":"2024-08-08T08:10:21.9134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generating New Text","metadata":{}},{"cell_type":"code","source":"def generate_entences(markov, limit=100, start='i am'):\n    n = 0\n    curr_state = start\n    next_state = None\n    story = \"\"\n    story += curr_state+\" \"\n    while n < limit:\n        next_state = random.choices(\n            list(markov[curr_state].keys()),\n            list(markov[curr_state].values()))\n \n        curr_state = next_state[0]\n        story += curr_state+\" \"\n        n += 1\n    return story\n \n# Generate 10 senetences\nfor i in range(10):\n    print(str(i)+\". \", generate_entences(\n        markov.get_model(), start='you are', limit=7))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:10:21.915048Z","iopub.status.idle":"2024-08-08T08:10:21.915408Z","shell.execute_reply.started":"2024-08-08T08:10:21.915233Z","shell.execute_reply":"2024-08-08T08:10:21.915249Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
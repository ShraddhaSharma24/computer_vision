Chest X-ray Classification

üìå Project Overview

This project focuses on automatic classification of chest X-ray images into normal and pneumonia cases using deep learning. The goal is to leverage convolutional neural networks (CNNs) to aid in the early detection of pneumonia from X-ray scans, which can assist radiologists and healthcare professionals.

üóÇ Dataset

Source: The dataset used in this project is the Chest X-ray Dataset (Pneumonia) from Kaggle.

Classes:

Normal (Healthy lungs)

Pneumonia (Lungs affected by bacterial/viral infection)

Structure:

train/: Training images

test/: Test images

val/: Validation images

üèó Methodology

Data Preprocessing

Load images using PyTorch datasets and DataLoader

Convert images to grayscale (1 channel)

Resize images to 224x224

Normalize pixel values (between 0 and 1)

Model Architecture

Convolutional Neural Network (CNN) with:

Convolutional layers (feature extraction)

Max pooling layers (dimensionality reduction)

Fully connected layers (classification)

Alternative Approach: Transfer learning with ResNet or EfficientNet

Training & Optimization

Loss function: Binary Cross Entropy Loss (BCELoss)

Optimizer: Adam

Learning rate scheduling for improved convergence

Evaluation

Metrics: Accuracy, Precision, Recall, F1-score

Confusion Matrix for class-wise performance

Grad-CAM for model explainability (optional)

‚öô Installation & Setup

To run this project, install the dependencies:

pip install torch torchvision matplotlib numpy opencv-python

Run the training script:

python train.py

Run evaluation on test images:

python evaluate.py

üéØ Results

Achieved X% accuracy on the test dataset.

Precision/Recall values indicate the model's performance in distinguishing normal vs. pneumonia cases.

üöÄ Future Improvements

Use Data Augmentation (rotation, flipping, brightness variations)

Optimize Hyperparameters (batch size, learning rate, number of layers)

Deploy the model using Flask/Streamlit for real-world usability

Interpretability: Apply Grad-CAM to visualize which areas the model focuses on while making predictions
